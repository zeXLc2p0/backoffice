#!/usr/bin/env python3
import argparse
import os
import json
import math
import numpy as np
import pandas as pd
import requests
import logging
import id3c.cli.redcap as redcap
from sys import stderr
from typing import Any, Dict

LOG_LEVEL = os.environ.get("LOG_LEVEL", "debug").upper()

logging.basicConfig(
    level = logging.ERROR,
    format = "[%(asctime)s] %(levelname)-8s %(message)s",
    datefmt = "%Y-%m-%d %H:%M:%S%z",
    stream = stderr)

logging.captureWarnings(True)

log = logging.getLogger(__name__)
log.setLevel(LOG_LEVEL)


# Import UW reopening records into the EHS Transfer REDCap project (#24025)
if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description= __doc__,
        formatter_class=argparse.RawTextHelpFormatter
    )

    parser.add_argument("filename",
        metavar="<input-file.csv>",
        help="An CSV file containing the data to import into EHS REDCap project")

    args = parser.parse_args()

    project = redcap.Project("https://redcap.iths.org", 24025)

    ehs_dataset = pd.read_csv(args.filename)

    # Post data to REDCap in batches of 10000 records to reduce strain on REDCap servers
    ehs_dataset_num_rows = ehs_dataset.shape[0]
    redcap_post_batch_size = 10000
    num_batches = math.ceil(ehs_dataset_num_rows / redcap_post_batch_size)

    for batch in np.array_split(ehs_dataset, num_batches):
        project.update_records(batch.to_dict(orient='records'), date_format = "MDY")
